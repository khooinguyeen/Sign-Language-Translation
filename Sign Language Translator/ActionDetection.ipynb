{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tải và import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow==2.5.0 tensorflow-gpu==2.5.0 opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Nhận diện và vẽ keypoints bằng mediapipe holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_hands.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_hands.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_hands.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break when type 'q'\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11240/1858948676.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_hand_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'landmark'"
     ]
    }
   ],
   "source": [
    "len(results.left_hand_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_landmarks(frame, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lấy ra các giá trị keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(results.left_hand_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose = []\n",
    "# for res in results.pose_landmarks.landmark:\n",
    "#     test = np.array([res.x, res.y, res.z, res.visibility])\n",
    "#     pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "# face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "# lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "# rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() \n",
    "#     if results.face_landmarks \n",
    "#     else np.zeros(1404)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_test = extract_keypoints(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 468*3+33*4+21*3+21*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('0', result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.load('0.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Thiết lập folder để lấy dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('Data') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['toi yeu ban', 'xoa di'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hello\n",
    "## 0\n",
    "## 1\n",
    "## 2\n",
    "## ...\n",
    "## 29\n",
    "# thanks\n",
    "\n",
    "# I love you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions: \n",
    "    for sequence in range(no_sequences):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Lấy các giá trị keypoints để train và test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# # Set mediapipe model \n",
    "# with mp_hands.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "#     # NEW LOOP\n",
    "#     # Loop through actions\n",
    "#     for action in actions:\n",
    "#         # Loop through sequences aka videos\n",
    "#         for sequence in range(no_sequences):\n",
    "#             # Loop through video length aka sequence length\n",
    "#             for frame_num in range(sequence_length):\n",
    "\n",
    "#                 # Read feed\n",
    "#                 ret, frame = cap.read()\n",
    "\n",
    "#                 # Make detections\n",
    "#                 image, results = mediapipe_detection(frame, holistic)\n",
    "# #                 print(results)\n",
    "\n",
    "#                 # Draw landmarks\n",
    "#                 draw_styled_landmarks(image, results)\n",
    "                \n",
    "#                 # NEW Apply wait logic\n",
    "#                 if frame_num == 0: \n",
    "#                     cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "#                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "#                     cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "#                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                     # Show to screen\n",
    "#                     cv2.imshow('OpenCV Feed', image)\n",
    "#                     cv2.waitKey(2000)\n",
    "#                 else: \n",
    "#                     cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "#                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                     # Show to screen\n",
    "#                     cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "#                 # NEW Export keypoints\n",
    "#                 keypoints = extract_keypoints(results)\n",
    "#                 npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "#                 np.save(npy_path, keypoints)\n",
    "\n",
    "#                 # Break gracefully\n",
    "#                 if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#                     break\n",
    "                    \n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Xử lý dữ liệu và gắn label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xin chao': 0,\n",
       " 'cam on': 1,\n",
       " 'toi yeu ban': 2,\n",
       " 'ban khoe khong': 3,\n",
       " 'ban ten gi': 4,\n",
       " 'toi so': 5,\n",
       " 'toi no roi': 6,\n",
       " 'toi rat vui': 7,\n",
       " 'toi la nguoi diec': 8,\n",
       " 'toi bi om': 9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(actions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 30, 126)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 30, 126)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 30, 126)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 30, 126)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Xây dựng và train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,126)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [.7, 0.2, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xin chao'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8/8 [==============================] - 6s 147ms/step - loss: 2.2745 - categorical_accuracy: 0.1333\n",
      "Epoch 2/40\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 1.9681 - categorical_accuracy: 0.2500\n",
      "Epoch 3/40\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 1.6905 - categorical_accuracy: 0.3750\n",
      "Epoch 4/40\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.3706 - categorical_accuracy: 0.4875\n",
      "Epoch 5/40\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.3368 - categorical_accuracy: 0.5208\n",
      "Epoch 6/40\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.3230 - categorical_accuracy: 0.5500 0s - loss: 1.4425 - categorical_accu\n",
      "Epoch 7/40\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.1802 - categorical_accuracy: 0.6292\n",
      "Epoch 8/40\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.0419 - categorical_accuracy: 0.7500\n",
      "Epoch 9/40\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.9297 - categorical_accuracy: 0.7875 0s - loss: 1.0195 - categorical_ac\n",
      "Epoch 10/40\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.7660 - categorical_accuracy: 0.8125\n",
      "Epoch 11/40\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.9763 - categorical_accuracy: 0.7583\n",
      "Epoch 12/40\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.2181 - categorical_accuracy: 0.6500\n",
      "Epoch 13/40\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.1558 - categorical_accuracy: 0.6500\n",
      "Epoch 14/40\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.8630 - categorical_accuracy: 0.7208\n",
      "Epoch 15/40\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.7039 - categorical_accuracy: 0.7667\n",
      "Epoch 16/40\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.5478 - categorical_accuracy: 0.8125\n",
      "Epoch 17/40\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.5548 - categorical_accuracy: 0.8000\n",
      "Epoch 18/40\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.4700 - categorical_accuracy: 0.8375\n",
      "Epoch 19/40\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.4320 - categorical_accuracy: 0.8792 0s - loss: 0.3641 - categorical_ac\n",
      "Epoch 20/40\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.3798 - categorical_accuracy: 0.9000 0s - loss: 0.4076 - categorical_accura\n",
      "Epoch 21/40\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.3015 - categorical_accuracy: 0.9000\n",
      "Epoch 22/40\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.5235 - categorical_accuracy: 0.9000\n",
      "Epoch 23/40\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.3186 - categorical_accuracy: 0.9000\n",
      "Epoch 24/40\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.1979 - categorical_accuracy: 0.9583\n",
      "Epoch 25/40\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.1435 - categorical_accuracy: 0.9583\n",
      "Epoch 26/40\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.1629 - categorical_accuracy: 0.9458 0s - loss: 0.1366 - categorical_accu\n",
      "Epoch 27/40\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.5559 - categorical_accuracy: 0.8417\n",
      "Epoch 28/40\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 0.5631 - categorical_accuracy: 0.8083\n",
      "Epoch 29/40\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.3233 - categorical_accuracy: 0.8833\n",
      "Epoch 30/40\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.3213 - categorical_accuracy: 0.9208\n",
      "Epoch 31/40\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.3126 - categorical_accuracy: 0.8917\n",
      "Epoch 32/40\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.1823 - categorical_accuracy: 0.9500\n",
      "Epoch 33/40\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2054 - categorical_accuracy: 0.9375\n",
      "Epoch 34/40\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.1736 - categorical_accuracy: 0.9500\n",
      "Epoch 35/40\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1130 - categorical_accuracy: 0.9625\n",
      "Epoch 36/40\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0813 - categorical_accuracy: 0.9792\n",
      "Epoch 37/40\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0933 - categorical_accuracy: 0.9708\n",
      "Epoch 38/40\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0549 - categorical_accuracy: 0.9833\n",
      "Epoch 39/40\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.5281 - categorical_accuracy: 0.9708\n",
      "Epoch 40/40\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.4949 - categorical_accuracy: 0.8917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29f169ceb80>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=40, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 30, 64)            48896     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 128)           98816     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 203,690\n",
      "Trainable params: 203,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Dự đoán bằng hàm predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toi bi om'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toi bi om'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Models/test1.h5') # main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11812/2039233898.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Models/action.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_model('Models/action.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Ước lượng bằng Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[47,  0],\n",
       "        [ 0, 13]],\n",
       "\n",
       "       [[59,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[56,  0],\n",
       "        [ 0,  4]],\n",
       "\n",
       "       [[52,  0],\n",
       "        [ 1,  7]],\n",
       "\n",
       "       [[57,  0],\n",
       "        [ 0,  3]],\n",
       "\n",
       "       [[55,  0],\n",
       "        [ 0,  5]],\n",
       "\n",
       "       [[51,  1],\n",
       "        [ 0,  8]],\n",
       "\n",
       "       [[56,  0],\n",
       "        [ 0,  4]],\n",
       "\n",
       "       [[54,  0],\n",
       "        [ 1,  5]],\n",
       "\n",
       "       [[51,  1],\n",
       "        [ 0,  8]]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[13  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  4  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  7  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  8  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  4  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  5  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(ytrue, yhat)\n",
    "print('Confusion matrix:')\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1, keepdims = True)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0, 1, 2, 3, 4, 5, 6, 7, 8,9]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13316/2909910892.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob_viz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.imshow(prob_viz(res, actions, image, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence.append('def')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 27ms/step - loss: 0.4509 - categorical_accuracy: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4509377181529999, 0.9833333492279053]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.62733257,  0.44471735, -0.69024068, ...,  0.40363967,\n",
       "         0.28696212, -0.06274992]),\n",
       " array([ 0.62688404,  0.4438577 , -0.73676074, ...,  0.40629318,\n",
       "         0.28771287, -0.05781016]),\n",
       " array([ 0.62661999,  0.44294813, -0.7216031 , ...,  0.40591961,\n",
       "         0.28609812, -0.06014785]),\n",
       " array([ 0.62655252,  0.44137394, -0.65666282, ...,  0.40555608,\n",
       "         0.28700155, -0.06166872]),\n",
       " array([ 0.6264345 ,  0.43732077, -0.64333224, ...,  0.40387231,\n",
       "         0.28911069, -0.06399857]),\n",
       " array([ 0.6262821 ,  0.43725368, -0.62972653, ...,  0.40475827,\n",
       "         0.29045084, -0.05971628]),\n",
       " array([ 0.6263392 ,  0.43722284, -0.63863361, ...,  0.40456492,\n",
       "         0.29014641, -0.06776936]),\n",
       " array([ 0.62639326,  0.43711936, -0.69808131, ...,  0.40482497,\n",
       "         0.28957966, -0.06049867]),\n",
       " array([ 0.62548095,  0.43673155, -0.58750856, ...,  0.40362868,\n",
       "         0.29177704, -0.05661049]),\n",
       " array([ 0.62491542,  0.43662712, -0.57843322, ...,  0.39947596,\n",
       "         0.29348499, -0.05010486]),\n",
       " array([ 0.62256533,  0.43746862, -0.59441966, ...,  0.39496863,\n",
       "         0.29602301, -0.05663034]),\n",
       " array([ 0.62216419,  0.43501934, -0.69985718, ...,  0.38580206,\n",
       "         0.29433241, -0.05569796]),\n",
       " array([ 0.61646301,  0.43266755, -0.61713064, ...,  0.32818383,\n",
       "         0.28491369, -0.06333546]),\n",
       " array([ 0.59957933,  0.41540986, -0.54605776, ...,  0.13947821,\n",
       "         0.46056941, -0.05800109]),\n",
       " array([ 0.56859589,  0.39313382, -0.56196642, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.53398085,  0.37075907, -0.64856064, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.49155292,  0.35332954, -0.86677265, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.41328245,  0.55472225, -0.58511895, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.35902414,  0.68084824, -0.75083447, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.34483343,  0.60933989, -1.31080616, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.37968573,  0.56897789, -1.09150004, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.47196683,  0.53704393, -1.09585977, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.4748559 ,  0.49132904, -1.06378198, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.33660218,  0.46825913, -0.67547524, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.32473943,  0.55345446, -0.63236827, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.35061374,  0.5645771 , -0.7478748 , ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.36148924,  0.55834323, -0.72135329, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.3823894 ,  0.54880404, -0.76922882, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.405047  ,  0.54266065, -0.87596643, ...,  0.        ,\n",
       "         0.        ,  0.        ]),\n",
       " array([ 0.46348   ,  0.51147842, -0.9253664 , ...,  0.        ,\n",
       "         0.        ,  0.        ])]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "ban khoe khong\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "ban khoe khong\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "ban khoe khong\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "ban khoe khong\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "ban khoe khong\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "ban khoe khong\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "ban khoe khong\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "ban khoe khong\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "ban khoe khong\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_hands.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read() # đọc video từ camera\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic) # gọi biến image và result = giá trị RGB của ảnh\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results) # nhận diện cơ thể \n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results) # xuất ra array các keypoints cơ thể (mấy cái đốt í)\n",
    "#         sequence.insert(0,keypoints)\n",
    "#         sequence = sequence[:30]\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:] # Đưa các frame thu đc vào mảng sequence, ở đây t để là 30 frame cuối\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)]) # Nếu thu đủ số frame của câu, đưa các array đấy vào model rồi ước lượng ra kết quả chính xác nhất trong dữ liệu\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                if len(sentence) > 0: \n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            # image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[np.argmax(res)] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (num_sequences,30,1662)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06465654, 0.2806947 , 0.6546488 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(X_test[0], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Thu thập thêm dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('Data') \n",
    "\n",
    "# Input data name\n",
    "new_action = input(\"Enter new data name: \")\n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.append(actions, new_action)\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 120\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xin chao' 'cam on' 'toi yeu ban' 'ban khoe khong' 'ban ten gi' 'toi so'\n",
      " 'toi no roi' 'toi rat vui' 'toi la nguoi diec']\n"
     ]
    }
   ],
   "source": [
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sequence in range(no_sequences):\n",
    "    try: \n",
    "        os.makedirs(os.path.join(DATA_PATH, new_action, str(sequence)))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_hands.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "# NEW LOOP\n",
    "# Loop through actions\n",
    "# for action in actions:\n",
    "    # Loop through sequences aka videos\n",
    "    for sequence in range(no_sequences):\n",
    "        # Loop through video length aka sequence length\n",
    "        for frame_num in range(sequence_length):\n",
    "\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Make detections\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "                # print(results)\n",
    "\n",
    "            # Draw landmarks\n",
    "            draw_styled_landmarks(image, results)\n",
    "            \n",
    "            # NEW Apply wait logic\n",
    "            if frame_num == 0: \n",
    "                cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(new_action, sequence), (15,12), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                # Show to screen\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                cv2.waitKey(2000)\n",
    "                \n",
    "            else: \n",
    "                cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(new_action, sequence), (15,12), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                # Show to screen\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "            \n",
    "            # NEW Export keypoints\n",
    "            keypoints = extract_keypoints(results)\n",
    "            npy_path = os.path.join(DATA_PATH, new_action, str(sequence), str(frame_num))\n",
    "            np.save(npy_path, keypoints)\n",
    "\n",
    "            # Break gracefully\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "                    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp856tuivr\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "keras_model = tf.keras.models.load_model(\"Models/sign.h5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT] # sử dụng optimization nếu cần tối ưu thêm\n",
    "tflite_model = converter.convert()\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input details [{'name': 'lstm_input', 'index': 0, 'shape': array([   1,   30, 1662]), 'shape_signature': array([  -1,   30, 1662]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "ouput details [{'name': 'Identity', 'index': 75, 'shape': array([1, 3]), 'shape_signature': array([-1,  3]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "#SHOW TFLITE MODEL RESULT\n",
    "\n",
    "import tensorflow as tf\n",
    "interpreter = tf.lite.Interpreter(model_path=\"Models/SignModel.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"input details\", input_details)\n",
    "print(\"ouput details\", output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74122477 0.2575568  0.00121851]\n"
     ]
    }
   ],
   "source": [
    "# TEST MODEL TFLITE\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"Models/SignModel.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_data = np.random.rand(1, 30, 1662).astype(np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support import flatbuffers\n",
    "from tflite_support import metadata as _metadata\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "\n",
    "\n",
    "\n",
    "# Creates model info.\n",
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = \"Sign Language Translation\"\n",
    "model_meta.description = (\"Identify the sign language and translate into\"\n",
    "                          \"text\")\n",
    "model_meta.version = \"v1\"\n",
    "model_meta.author = \"khooinguyeen\"\n",
    "model_meta.license = (\"Apache License. Version 2.0 \"\n",
    "                      \"http://www.apache.org/licenses/LICENSE-2.0.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcacb0086e9a4f4eabd41c33bf4faac5ea0a3337ed3f5eff0680afa930572c04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
